# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

"""
ReActNet-YOLO è®­ç»ƒè„šæœ¬ï¼ˆæ”¯æŒçŸ¥è¯†è’¸é¦å’Œå¤šå¡è®­ç»ƒï¼‰

ä½¿ç”¨æ–¹æ³•:
    # å•å¡è®­ç»ƒ
    python main.py --model yolov8n-react.yaml --data coco.yaml --epochs 150
    # å¤šå¡è®­ç»ƒ (4å¼ å¡)
    torchrun --nproc_per_node=4 main.py --model yolov8n-react.yaml --data coco.yaml --epochs 150 --batch 64
"""

from __future__ import annotations

import os
import math
import random
from pathlib import Path
from typing import Any

# ç¦ç”¨è‡ªåŠ¨ä¸‹è½½è­¦å‘Š
os.environ['AUTODOWNLOAD'] = '0'

import torch
import torch.nn as nn
import torch.optim as optim
import torch.distributed as dist
from torch.cuda.amp import autocast
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import DataLoader
from torch.utils.data.distributed import DistributedSampler
from tqdm import tqdm

from ultralytics import YOLO
from ultralytics.data import build_yolo_dataset
from ultralytics.nn.modules import Conv
from ultralytics.utils import LOGGER, TQDM, colorstr
from ultralytics.utils.loss import DistributionLoss
from ultralytics.utils.plotting import plot_results
from ultralytics.utils.torch_utils import unwrap_model
from ultralytics.utils import YAML


def init_distributed(local_rank: int):
    """åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒ"""
    if local_rank == -1:
        return False

    # æ£€æŸ¥æ˜¯å¦å·²ç»åˆå§‹åŒ–ï¼ˆé¿å…é‡å¤åˆå§‹åŒ–ï¼‰
    if dist.is_initialized():
        return True

    torch.cuda.set_device(local_rank)
    dist.init_process_group(backend='nccl', init_method='env://')
    return True


def cleanup():
    """æ¸…ç†åˆ†å¸ƒå¼ç¯å¢ƒ"""
    if dist.is_initialized():
        dist.destroy_process_group()


class KDTrainer:
    """
    çŸ¥è¯†è’¸é¦è®­ç»ƒå™¨ for ReActNet-YOLO

    ç‰¹ç‚¹:
    1. æ”¯æŒäºŒå€¼åŒ–æ¿€æ´»è®­ç»ƒ (BinaryConv/BinaryC2f)
    2. å¯é€‰çŸ¥è¯†è’¸é¦ (ä½¿ç”¨å…¨ç²¾åº¦æ•™å¸ˆæ¨¡å‹)
    3. æ”¯æŒå¤šå¡åˆ†å¸ƒå¼è®­ç»ƒ (DDP)
    4. é›†æˆ ReActNet è®­ç»ƒè¶…å‚æ•°
    """

    def __init__(self, overrides: dict | None = None, local_rank: int = -1):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨

        Args:
            cfg: é…ç½®æ–‡ä»¶è·¯å¾„æˆ–å­—å…¸
            overrides: å‚æ•°è¦†ç›–å­—å…¸
            local_rank: æœ¬åœ°è¿›ç¨‹æ’åï¼ˆç”¨äºDDPï¼‰
        """
        self.local_rank = local_rank
        self.rank = local_rank
        self.world_size = 1

        # åˆå§‹åŒ–åˆ†å¸ƒå¼
        self.distributed = init_distributed(local_rank)
        if self.distributed:
            self.rank = dist.get_rank()
            self.world_size = dist.get_world_size()
            if self.rank == 0:
                LOGGER.info(f"Distributed training enabled: {self.world_size} GPUs")

        # ç›´æ¥ä» overrides ä¸­æå–å‚æ•°ï¼Œä¸ä½¿ç”¨ get_cfg éªŒè¯
        self.model_path = overrides.get('model', 'yolov8n-react.yaml')
        self.data_path = overrides.get('data', '')
        self.epochs = overrides.get('epochs', 150)
        self.batch_size = overrides.get('batch', 32)
        self.img_size = overrides.get('imgsz', 640)

        # æ­£ç¡®å¤„ç†è®¾å¤‡å­—ç¬¦ä¸²
        device = overrides.get('device', '0')
        if device == '0':
            device = f'cuda:{local_rank}' if local_rank >= 0 else ('cuda:0' if torch.cuda.is_available() else 'cpu')
        self.device = device

        # å­¦ä¹ ç‡å‚æ•°
        self.lr0 = overrides.get('lr0', 0.001)
        self.lrf = overrides.get('lrf', 0.01)
        self.momentum = overrides.get('momentum', 0.9)
        self.weight_decay = overrides.get('weight_decay', 1e-5)

        # è’¸é¦å‚æ•°
        self.teacher_path = overrides.get('teacher', None)
        self.kd_alpha = overrides.get('kd_alpha', 0.0)
        self.kd_temp = overrides.get('kd_temp', 1.0)

        # å…¶ä»–å‚æ•°
        self.save_dir = overrides.get('save_dir', 'runs/train')
        self.project = overrides.get('project', 'runs/train')
        self.name = overrides.get('name', 'exp')
        self.cos_lr = overrides.get('cos_lr', False)
        self.warmup_epochs = overrides.get('warmup_epochs', 3.0)
        self.amp = overrides.get('amp', True)
        self.val = overrides.get('val', True)
        self.save_period = overrides.get('save_period', -1)
        self.plots = overrides.get('plots', True)
        self.workers = overrides.get('workers', 8)

        # åŠ è½½æ•°æ®é…ç½®ï¼ˆç”¨äº build_yolo_datasetï¼‰- ç›´æ¥ä½¿ç”¨ YAML è¯»å–ä¸ºå­—å…¸
        self.data = YAML.load(self.data_path)

        # åˆ›å»º args å¯¹è±¡ä¾› build_yolo_dataset ä½¿ç”¨ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„è¶…å‚æ•°
        # ä½¿ç”¨ get_cfg åŠ è½½é»˜è®¤é…ç½®å¹¶åˆå¹¶
        from ultralytics.cfg import get_cfg, DEFAULT_CFG_DICT
        # åˆ›å»ºè‡ªå®šä¹‰é…ç½®ï¼Œè¦†ç›–é»˜è®¤çš„ data è·¯å¾„ï¼ˆé¿å…ä¸‹è½½ coco8ï¼‰
        custom_cfg = dict(DEFAULT_CFG_DICT)
        custom_cfg['data'] = self.data_path
        self.args = get_cfg(custom_cfg, {
            'imgsz': self.img_size,
            'batch': self.batch_size,
            'device': self.device,
            'workers': self.workers,
            'amp': self.amp,
            'fraction': 1.0,
            'task': 'detect',
        })
        # æ·»åŠ è®­ç»ƒå¿…éœ€çš„å±æ€§
        self.args.stride = 32
        self.args.rect = False
        self.args.cache = None
        self.args.single_cls = False
        self.args.mode = 'cache'
        self.args.classes = None

        # åˆå§‹åŒ–ç»„ä»¶
        self.model = None
        self.teacher_model = None
        self.optimizer = None
        self.scheduler = None
        self.scaler = torch.cuda.amp.GradScaler()
        self.train_loader = None
        self.val_loader = None

        # æŸå¤±å‡½æ•°
        self.kd_criterion = DistributionLoss()

        if self.rank == 0:
            LOGGER.info(f"{colorstr('bold', 'ReActNet-YOLO KDTrainer')}")
            LOGGER.info(f"  - Model: {self.model_path}")
            LOGGER.info(f"  - Data: {self.data_path}")
            LOGGER.info(f"  - Epochs: {self.epochs}")
            LOGGER.info(f"  - Batch: {self.batch_size} ({self.batch_size // max(1, self.world_size)} per GPU)")
            LOGGER.info(f"  - LR: {self.lr0}")
            if self.teacher_path:
                LOGGER.info(f"  - Teacher: {self.teacher_path}")
                LOGGER.info(f"  - KD Alpha: {self.kd_alpha}, Temp: {self.kd_temp}")

    def setup_model(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        if self.rank == 0:
            LOGGER.info("-" * 60)
            LOGGER.info("Setting up model...")

        # ç¡®ä¿åˆ†å¸ƒå¼è¿›ç¨‹ç»„å·²åˆå§‹åŒ–
        self._ensure_distributed_init()

        # åŠ è½½å­¦ç”Ÿæ¨¡å‹
        self.model = YOLO(self.model_path)
        self.model.to(self.device)

        # å¤šå¡åˆ†å¸ƒå¼åŒ…è£…
        if self.distributed:
            self.model = DDP(self.model, device_ids=[self.local_rank], output_device=self.local_rank)

        # åŠ è½½æ•™å¸ˆæ¨¡å‹ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
        if self.teacher_path and self.rank == 0:
            self._setup_teacher_model()

        if self.rank == 0:
            LOGGER.info("Model setup complete.")

    def _setup_teacher_model(self):
        """è®¾ç½®æ•™å¸ˆæ¨¡å‹"""
        LOGGER.info(f"Loading teacher model: {self.teacher_path}")
        self.teacher_model = YOLO(self.teacher_path)
        self.teacher_model.fuse()
        self.teacher_model.info()
        self.teacher_model.to(self.device)
        self.teacher_model.eval()

        # å†»ç»“æ•™å¸ˆæ¨¡å‹
        for param in self.teacher_model.parameters():
            param.requires_grad = False

        LOGGER.info("Teacher model loaded and frozen.")

    def setup_dataloader(self):
        """æ„å»ºæ•°æ®åŠ è½½å™¨"""
        if self.rank == 0:
            LOGGER.info("-" * 60)
            LOGGER.info("Setting up dataloaders...")

        # ç¡®ä¿åˆ†å¸ƒå¼è¿›ç¨‹ç»„å·²åˆå§‹åŒ–ï¼ˆç”¨äºDistributedSamplerï¼‰
        self._ensure_distributed_init()

        # ä»æ•°æ®é…ç½®ä¸­è·å–è®­ç»ƒå’ŒéªŒè¯è·¯å¾„
        train_img_path = self.data.get('train', '')
        val_img_path = self.data.get('val', '')

        # è®­ç»ƒæ•°æ®é›†
        train_dataset = build_yolo_dataset(
            self.args, train_img_path, self.batch_size, self.data, mode='train', stride=32
        )

        # ä½¿ç”¨åˆ†å¸ƒå¼é‡‡æ ·å™¨
        sampler = DistributedSampler(
            train_dataset,
            num_replicas=self.world_size,
            rank=self.rank,
            shuffle=True,
            drop_last=True,
            seed=0,
        ) if self.distributed else None

        # è®¡ç®—å®é™… batch size per GPU
        batch_per_gpu = self.batch_size // max(1, self.world_size)

        self.train_loader = DataLoader(
            train_dataset,
            batch_size=batch_per_gpu,
            shuffle=(sampler is None),
            sampler=sampler,
            num_workers=self.args.workers,
            pin_memory=True,
            collate_fn=train_dataset.collate_fn,
            drop_last=True,
        )

        # éªŒè¯æ•°æ®é›†ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
        if self.val and val_img_path and self.rank == 0:
            val_dataset = build_yolo_dataset(
                self.args, val_img_path, self.batch_size, self.data, mode='val', stride=32
            )
            self.val_loader = DataLoader(
                val_dataset,
                batch_size=self.batch_size,
                shuffle=False,
                num_workers=self.args.workers,
                pin_memory=True,
                collate_fn=val_dataset.collate_fn,
            )

        if self.rank == 0:
            LOGGER.info(f"Train batches: {len(self.train_loader)}")

    def setup_optimizer(self):
        """è®¾ç½®ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        if self.rank == 0:
            LOGGER.info("-" * 60)
            LOGGER.info("Setting up optimizer...")

        # ä¼˜åŒ–å™¨
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=self.lr0,
            weight_decay=self.weight_decay,
        )

        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        if self.cos_lr:
            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer,
                T_max=self.epochs,
                eta_min=self.lr0 * self.lrf,
            )
        else:
            self.scheduler = optim.lr_scheduler.StepLR(
                self.optimizer,
                step_size=30,
                gamma=0.1,
            )

        if self.rank == 0:
            LOGGER.info(f"Optimizer: AdamW, LR: {self.lr0}, WD: {self.weight_decay}")

    def _get_kd_loss(self, student_scores, images):
        """è®¡ç®—è’¸é¦æŸå¤±"""
        if self.teacher_model is None or self.kd_alpha == 0:
            return torch.tensor(0.0, device=self.device)

        with torch.no_grad():
            teacher_output = self.teacher_model(images)
            # æå–åˆ†ç±»åˆ†æ•°
            if isinstance(teacher_output, (list, tuple)):
                teacher_output = teacher_output[0]

        # åº”ç”¨æ¸©åº¦ç¼©æ”¾
        student_logits = student_scores / self.kd_temp
        teacher_logits = teacher_output / self.kd_temp

        # è®¡ç®—KLæ•£åº¦
        kd_loss = self.kd_criterion(student_logits, teacher_logits)
        kd_loss = kd_loss * (self.kd_temp ** 2)

        return kd_loss

    def _ensure_distributed_init(self):
        """ç¡®ä¿åˆ†å¸ƒå¼è¿›ç¨‹ç»„å·²åˆå§‹åŒ–"""
        if self.distributed and not dist.is_initialized():
            if self.rank == 0:
                LOGGER.info("Initializing distributed process group...")
            torch.cuda.set_device(self.local_rank)
            dist.init_process_group(backend='nccl', init_method='env://')
            # åŒæ­¥æ‰€æœ‰è¿›ç¨‹
            dist.barrier()

    def train_one_epoch(self, epoch: int) -> dict:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        # ç¡®ä¿åˆ†å¸ƒå¼è¿›ç¨‹ç»„å·²åˆå§‹åŒ–ï¼ˆYOLOå†…éƒ¨trainerå¯èƒ½ä¼šç”¨åˆ°ï¼‰
        self._ensure_distributed_init()
        self.model.train()

        # è®¾ç½®åˆ†å¸ƒå¼é‡‡æ ·å™¨ epoch
        if hasattr(self.train_loader, 'sampler'):
            self.train_loader.sampler.set_epoch(epoch)

        pbar = TQDM(self.train_loader, desc=f"Epoch {epoch+1}/{self.epochs}") if self.rank == 0 else None

        total_loss = 0
        total_kd_loss = 0
        num_batches = 0

        for batch_idx, batch in enumerate(self.train_loader):
            images = batch["img"].to(self.device)
            targets = batch["bboxes"].to(self.device)
            batch_idx = batch["batch_idx"].to(self.device)
            cls = batch["cls"].to(self.device)

            # æ··åˆç²¾åº¦
            with autocast(self.amp):
                # å‰å‘ä¼ æ’­
                results = self.model(images)
                loss, loss_items = results[0], results[1]

                # è’¸é¦æŸå¤±
                kd_loss = torch.tensor(0.0, device=self.device)
                if self.teacher_model is not None and self.rank == 0:
                    # æå–åˆ†ç±»åˆ†æ•°
                    student_scores = self._extract_class_scores(results)
                    kd_loss = self._get_kd_loss(student_scores, images)

                # æ€»æŸå¤±
                total_batch_loss = loss + self.kd_alpha * kd_loss

            # åå‘ä¼ æ’­
            self.scaler.scale(total_batch_loss).backward()
            self.scaler.step(self.optimizer)
            self.scaler.update()
            self.optimizer.zero_grad()

            # ç»Ÿè®¡
            total_loss += loss.item()
            total_kd_loss += kd_loss.item() if isinstance(kd_loss, torch.Tensor) else kd_loss
            num_batches += 1

            # æ›´æ–°è¿›åº¦æ¡ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
            if pbar is not None:
                loss_dict = {"loss": loss.item(), "kd": kd_loss.item() if isinstance(kd_loss, torch.Tensor) else 0}
                pbar.set_postfix(**{k: f"{v:.4f}" for k, v in loss_dict.items()})

        # åŒæ­¥æ‰€æœ‰è¿›ç¨‹çš„æŸå¤±
        if self.distributed:
            total_loss = torch.tensor(total_loss, device=self.device)
            total_kd_loss = torch.tensor(total_kd_loss, device=self.device)
            num_batches = torch.tensor(num_batches, device=self.device)

            dist.all_reduce(total_loss, op=dist.ReduceOp.SUM)
            dist.all_reduce(total_kd_loss, op=dist.ReduceOp.SUM)
            dist.all_reduce(num_batches, op=dist.ReduceOp.SUM)

            total_loss = total_loss.item() / self.world_size
            total_kd_loss = total_kd_loss.item() / self.world_size
            num_batches = int(num_batches.item() / self.world_size)

        # å­¦ä¹ ç‡è°ƒåº¦
        self.scheduler.step()

        avg_loss = total_loss / num_batches
        avg_kd_loss = total_kd_loss / num_batches

        return {"loss": avg_loss, "kd_loss": avg_kd_loss}

    def _extract_class_scores(self, results):
        """ä»æ¨¡å‹è¾“å‡ºä¸­æå–åˆ†ç±»åˆ†æ•°"""
        # YOLO è¾“å‡ºç»“æ„: [loss, loss_items, predictions]
        # predictions æ˜¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªæ£€æµ‹å¤´çš„è¾“å‡º
        if len(results) >= 3:
            predictions = results[2]
            if isinstance(predictions, list):
                # å–ç¬¬ä¸€ä¸ªæ£€æµ‹å¤´çš„åˆ†ç±»è¾“å‡º
                m = self.model.module.model[-1] if hasattr(self.model, 'module') else self.model.model[-1]
                pred_distri, pred_scores = torch.cat(
                    [p.view(p.shape[0], m.no, -1) for p in predictions], 2
                ).split((m.reg_max * 4, m.nc), 1)
                return pred_scores
        return None

    @torch.no_grad()
    def validate(self) -> dict:
        """éªŒè¯"""
        if not self.val or self.rank != 0:
            return {}

        self.model.eval()
        metrics = self.model.val(
            data=self.data_path,
            batch=self.batch_size,
            imgsz=self.img_size,
            device=self.device,
            save_json=False,
        )

        return metrics

    def save_model(self, epoch: int, metrics: dict | None = None):
        """ä¿å­˜æ¨¡å‹ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰"""
        if self.rank != 0:
            return

        save_path = Path(self.save_dir) / self.name / f"epoch_{epoch+1}.pt"
        save_path.parent.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜é DDP æ¨¡å‹
        model_to_save = self.model.module if hasattr(self.model, 'module') else self.model
        model_to_save.save(save_path)
        LOGGER.info(f"Saved model to {save_path}")

    def train(self):
        """å¼€å§‹è®­ç»ƒ"""
        if self.rank == 0:
            LOGGER.info("=" * 60)
            LOGGER.info(f"Starting training for {self.epochs} epochs...")
            LOGGER.info("=" * 60)

        # åˆå§‹åŒ–
        self.setup_model()
        self.setup_dataloader()
        self.setup_optimizer()

        best_mAP = 0
        history = []

        for epoch in range(self.epochs):
            # è®­ç»ƒ
            train_metrics = self.train_one_epoch(epoch)

            # éªŒè¯ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
            if self.val and (epoch + 1) % 10 == 0:
                val_metrics = self.validate()
                if val_metrics:
                    mAP50 = val_metrics.box.map50 if hasattr(val_metrics, 'box') else 0
                    mAP = val_metrics.box.map if hasattr(val_metrics, 'box') else 0

                    if self.rank == 0:
                        LOGGER.info(f"Validation: mAP50={mAP50:.4f}, mAP={mAP:.4f}")

                    if mAP > best_mAP:
                        best_mAP = mAP
                        self.save_model(epoch, val_metrics)
            elif self.save_period > 0 and (epoch + 1) % self.save_period == 0:
                self.save_model(epoch)

            # è®°å½•å†å²ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
            if self.rank == 0:
                history.append({
                    'epoch': epoch + 1,
                    'train_loss': train_metrics['loss'],
                    'kd_loss': train_metrics['kd_loss'],
                })
                LOGGER.info(f"Epoch {epoch+1}/{self.epochs} - Loss: {train_metrics['loss']:.4f}")

        if self.rank == 0:
            LOGGER.info("=" * 60)
            LOGGER.info("Training complete!")

            # ä¿å­˜æœ€ç»ˆæ¨¡å‹
            self.save_model(self.epochs - 1)

        # æ¸…ç†åˆ†å¸ƒå¼ç¯å¢ƒ
        cleanup()

        return history


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='ReActNet-YOLO Training')

    # åŸºæœ¬å‚æ•°
    parser.add_argument('--model', type=str, default='yolov8n-react.yaml', help='æ¨¡å‹é…ç½®æ–‡ä»¶')
    parser.add_argument('--data', type=str, required=True, help='æ•°æ®é›†é…ç½®æ–‡ä»¶')
    parser.add_argument('--epochs', type=int, default=150, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch', type=int, default=32, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--imgsz', type=int, default=640, help='å›¾åƒå°ºå¯¸')

    # å­¦ä¹ ç‡å‚æ•°
    parser.add_argument('--lr0', type=float, default=0.001, help='åˆå§‹å­¦ä¹ ç‡')
    parser.add_argument('--lrf', type=float, default=0.01, help='æœ€ç»ˆå­¦ä¹ ç‡æ¯”ä¾‹')
    parser.add_argument('--momentum', type=float, default=0.9, help='åŠ¨é‡')
    parser.add_argument('--weight_decay', type=float, default=1e-5, help='æƒé‡è¡°å‡')
    parser.add_argument('--cos_lr', action='store_true', help='ä½¿ç”¨ä½™å¼¦å­¦ä¹ ç‡')
    parser.add_argument('--warmup_epochs', type=float, default=2.0, help='çƒ­èº«è½®æ•°')

    # è’¸é¦å‚æ•°
    parser.add_argument('--teacher', type=str, default=None, help='æ•™å¸ˆæ¨¡å‹è·¯å¾„')
    parser.add_argument('--kd_alpha', type=float, default=0.5, help='è’¸é¦æŸå¤±æƒé‡')
    parser.add_argument('--kd_temp', type=float, default=2.0, help='è’¸é¦æ¸©åº¦')

    # å…¶ä»–å‚æ•°
    parser.add_argument('--device', type=str, default='0', help='è®¾å¤‡')
    parser.add_argument('--workers', type=int, default=8, help='æ•°æ®åŠ è½½çº¿ç¨‹æ•°')
    parser.add_argument('--project', type=str, default='runs/train', help='é¡¹ç›®åç§°')
    parser.add_argument('--name', type=str, default='exp', help='å®éªŒåç§°')
    parser.add_argument('--val', action='store_true', default=True, help='éªŒè¯')
    parser.add_argument('--save_period', type=int, default=-1, help='ä¿å­˜å‘¨æœŸ')
    parser.add_argument('--amp', action='store_true', default=True, help='æ··åˆç²¾åº¦')
    parser.add_argument('--cfg', type=str, default=None, help='é…ç½®æ–‡ä»¶è·¯å¾„')

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()

    # è·å–æœ¬åœ°è¿›ç¨‹æ’å
    local_rank = int(os.environ.get('LOCAL_RANK', -1))

    # æ„å»ºé…ç½®å­—å…¸
    overrides = {
        'model': args.model,
        'data': args.data,
        'epochs': args.epochs,
        'batch': args.batch,
        'imgsz': args.imgsz,
        'lr0': args.lr0,
        'lrf': args.lrf,
        'momentum': args.momentum,
        'weight_decay': args.weight_decay,
        'cos_lr': args.cos_lr,
        'warmup_epochs': args.warmup_epochs,
        'teacher': args.teacher,
        'kd_alpha': args.kd_alpha,
        'kd_temp': args.kd_temp,
        'device': args.device,
        'workers': args.workers,
        'project': args.project,
        'name': args.name,
        'val': args.val,
        'save_period': args.save_period,
        'amp': args.amp,
    }

    # å¦‚æœæŒ‡å®šäº†é…ç½®æ–‡ä»¶ï¼Œä»yamlè¯»å–å¹¶åˆå¹¶
    if args.cfg:
        from ultralytics.cfg import get_cfg
        cfg_args = get_cfg(args.cfg, overrides)
        # å°†é…ç½®å¯¹è±¡è½¬ä¸ºå­—å…¸
        cfg_dict = {k: v for k, v in vars(cfg_args).items() if not k.startswith('_')}
        # åˆå¹¶åˆ° overridesï¼ˆå‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆçº§æ›´é«˜ï¼‰
        cfg_dict.update(overrides)
        trainer = KDTrainer(overrides=cfg_dict, local_rank=local_rank)
    else:
        trainer = KDTrainer(overrides=overrides, local_rank=local_rank)

    trainer.train()


if __name__ == "__main__":
    main()
