# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

"""
ReActNet-YOLO è®­ç»ƒè„šæœ¬ - ä¿®å¤ç‰ˆ (Ver2)

åŸºäº DetectionTrainer å®ç°çŸ¥è¯†è’¸é¦è®­ç»ƒ
ä½¿ç”¨å“åº”è’¸é¦ï¼šåœ¨æ£€æµ‹å¤´è¾“å‡ºå±‚é¢è¿›è¡ŒçŸ¥è¯†è’¸é¦
"""

from __future__ import annotations

import torch
import torch.nn as nn
import torch.nn.functional as F
from pathlib import Path
from typing import Any

from ultralytics.models.yolo.detect.train import DetectionTrainer
from ultralytics.utils import DEFAULT_CFG_DICT, LOGGER, RANK
from ultralytics.utils.loss import v8DetectionLoss
from ultralytics.utils.torch_utils import unwrap_model


class v8DetectionLossWithKD(v8DetectionLoss):
    """å¸¦çŸ¥è¯†è’¸é¦çš„ YOLOv8 æ£€æµ‹æŸå¤±ç±»ã€‚

    åœ¨åŸå§‹æ£€æµ‹æŸå¤±åŸºç¡€ä¸Šæ·»åŠ å“åº”è’¸é¦æŸå¤±ï¼Œ
    é€šè¿‡å¯¹é½å­¦ç”Ÿå’Œæ•™å¸ˆæ¨¡å‹çš„åˆ†ç±»åˆ†æ•°æ¥å®ç°çŸ¥è¯†è¿ç§»ã€‚
    """

    def __init__(self, model, tal_topk: int = 10, teacher_model=None, kd_alpha: float = 0.5, kd_temp: float = 2.0):
        """åˆå§‹åŒ–å¸¦ KD çš„æ£€æµ‹æŸå¤±ã€‚

        Args:
            model: å­¦ç”Ÿæ¨¡å‹
            tal_topk: Task-Aligned Assigner çš„ topk å‚æ•°
            teacher_model: æ•™å¸ˆæ¨¡å‹ï¼ˆç”¨äºè’¸é¦ï¼‰
            kd_alpha: è’¸é¦æŸå¤±æƒé‡
            kd_temp: è’¸é¦æ¸©åº¦
        """
        super().__init__(model, tal_topk)
        self.teacher_model = teacher_model
        self.kd_alpha = kd_alpha
        self.kd_temp = kd_temp
        self.kd_loss_fn = nn.KLDivLoss(reduction='batchmean')

    def set_teacher(self, teacher_model):
        """è®¾ç½®æ•™å¸ˆæ¨¡å‹ã€‚"""
        self.teacher_model = teacher_model

    def __call__(self, preds: Any, batch: dict[str, torch.Tensor]) -> tuple[torch.Tensor, torch.Tensor]:
        """è®¡ç®—æ£€æµ‹æŸå¤± + è’¸é¦æŸå¤±ã€‚"""
        # å…ˆè®¡ç®—åŸå§‹æ£€æµ‹æŸå¤±
        det_loss, loss_items = super().__call__(preds, batch)

        # å¦‚æœæ²¡æœ‰æ•™å¸ˆæ¨¡å‹ï¼Œç›´æ¥è¿”å›åŸå§‹æŸå¤±
        if self.teacher_model is None:
            return det_loss, loss_items

        # è®¡ç®—è’¸é¦æŸå¤±
        kd_loss = self._compute_kd_loss(preds, batch)

        # æ€»æŸå¤± = æ£€æµ‹æŸå¤± + alpha * è’¸é¦æŸå¤±
        total_loss = det_loss + self.kd_alpha * kd_loss

        # æ›´æ–° loss_itemsï¼ˆæ·»åŠ  kd_loss ç”¨äºæ—¥å¿—ï¼‰
        # loss_items æ˜¯ [box, cls, dfl]ï¼Œæˆ‘ä»¬ä¸ä¿®æ”¹å®ƒä»¥ä¿æŒå…¼å®¹æ€§
        # kd_loss ä¼šåœ¨è®­ç»ƒå¾ªç¯ä¸­å•ç‹¬è®°å½•

        return total_loss, loss_items

    def _compute_kd_loss(self, preds: Any, batch: dict[str, torch.Tensor]) -> torch.Tensor:
        """è®¡ç®—å“åº”è’¸é¦æŸå¤±ã€‚

        åœ¨æ£€æµ‹å¤´çš„åˆ†ç±»åˆ†æ•°å±‚é¢è¿›è¡Œè’¸é¦ã€‚
        """
        # æå–å­¦ç”Ÿæ¨¡å‹çš„ç‰¹å¾
        feats = preds[1] if isinstance(preds, tuple) else preds

        # è·å–å­¦ç”Ÿçš„åˆ†ç±»åˆ†æ•°
        student_pred_scores = torch.cat(
            [xi.view(feats[0].shape[0], self.no, -1) for xi in feats], 2
        ).split((self.reg_max * 4, self.nc), 1)[1]  # åªå–åˆ†ç±»åˆ†æ•°éƒ¨åˆ†

        # è·å–æ•™å¸ˆæ¨¡å‹çš„é¢„æµ‹
        with torch.no_grad():
            teacher_preds = self.teacher_model(batch["img"])
            teacher_feats = teacher_preds[1] if isinstance(teacher_preds, tuple) else teacher_preds

            # ç¡®ä¿æ•™å¸ˆæ¨¡å‹è¾“å‡ºæ ¼å¼æ­£ç¡®
            if isinstance(teacher_feats, (list, tuple)) and len(teacher_feats) > 0:
                # è·å–æ•™å¸ˆçš„åˆ†ç±»åˆ†æ•°
                teacher_no = self.no  # å‡è®¾æ•™å¸ˆå’Œå­¦ç”Ÿæœ‰ç›¸åŒçš„è¾“å‡ºé€šé“æ•°
                try:
                    teacher_pred_scores = torch.cat(
                        [xi.view(teacher_feats[0].shape[0], teacher_no, -1) for xi in teacher_feats], 2
                    ).split((self.reg_max * 4, self.nc), 1)[1]
                except Exception:
                    # å¦‚æœæ•™å¸ˆæ¨¡å‹ç»“æ„ä¸åŒï¼Œå°è¯•å…¶ä»–æ–¹å¼
                    return torch.tensor(0.0, device=self.device)
            else:
                return torch.tensor(0.0, device=self.device)

        # ç¡®ä¿å½¢çŠ¶åŒ¹é…
        if student_pred_scores.shape != teacher_pred_scores.shape:
            # å¦‚æœç©ºé—´ç»´åº¦ä¸åŒï¼Œè¿›è¡Œæ’å€¼å¯¹é½
            if student_pred_scores.shape[-1] != teacher_pred_scores.shape[-1]:
                min_len = min(student_pred_scores.shape[-1], teacher_pred_scores.shape[-1])
                student_pred_scores = student_pred_scores[..., :min_len]
                teacher_pred_scores = teacher_pred_scores[..., :min_len]

        # è®¡ç®— KL æ•£åº¦æŸå¤±
        # å¯¹åˆ†ç±»åˆ†æ•°åº”ç”¨æ¸©åº¦ç¼©æ”¾
        student_logits = student_pred_scores / self.kd_temp
        teacher_logits = teacher_pred_scores / self.kd_temp

        # Softmax over classes (dim=1)
        student_log_probs = F.log_softmax(student_logits, dim=1)
        teacher_probs = F.softmax(teacher_logits, dim=1)

        # KL æ•£åº¦æŸå¤±
        kd_loss = self.kd_loss_fn(student_log_probs, teacher_probs) * (self.kd_temp ** 2)

        return kd_loss


class ReActNetTrainer(DetectionTrainer):
    """ReActNet-YOLO è®­ç»ƒå™¨ï¼Œæ”¯æŒçŸ¥è¯†è’¸é¦ã€‚

    ç»§æ‰¿ DetectionTrainerï¼Œå¤ç”¨æ‰€æœ‰æ£€æµ‹è®­ç»ƒåŠŸèƒ½ï¼Œ
    é€šè¿‡è‡ªå®šä¹‰æŸå¤±ç±»å®ç°å“åº”è’¸é¦ã€‚
    """

    def __init__(self, cfg=None, overrides: dict | None = None, _callbacks=None):
        """åˆå§‹åŒ–è®­ç»ƒå™¨ã€‚"""
        if overrides is None:
            overrides = {}
        else:
            overrides = overrides.copy()  # åˆ›å»ºå‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸå§‹å­—å…¸

        # æå–è‡ªå®šä¹‰ KD å‚æ•°ï¼Œé¿å…è¢« check_dict_alignment æ£€æŸ¥
        self._kd_temp = overrides.pop('kd_temp', None)
        self._kd_alpha = overrides.pop('kd_alpha', None)
        self._teacher_path = overrides.pop('teacher', None)

        # åŠ è½½ reactnet_hyp.yaml ä¸­çš„è‡ªå®šä¹‰è¶…å‚æ•°å¹¶åˆå¹¶åˆ° overrides
        reactnet_hyp_path = Path(__file__).parent.parent.parent.parent / "cfg" / "reactnet_hyp.yaml"
        if reactnet_hyp_path.exists():
            from ultralytics.utils import YAML
            reactnet_cfg = YAML.load(reactnet_hyp_path)
            # å°† reactnet_hyp.yaml ä¸­çš„é…ç½®ä½œä¸ºé»˜è®¤å€¼ï¼Œoverrides ä¼˜å…ˆ
            for k, v in reactnet_cfg.items():
                if k not in overrides and v is not None:
                    # è·³è¿‡ KD ç›¸å…³å‚æ•°ï¼Œå› ä¸ºå·²ç»å•ç‹¬å¤„ç†äº†
                    if k not in ('teacher', 'kd_alpha', 'kd_temp'):
                        overrides[k] = v

        # ä½¿ç”¨ DEFAULT_CFG_DICT ä½œä¸ºåŸºç¡€é…ç½®ï¼ˆåŒ…å«æ‰€æœ‰å¿…éœ€å‚æ•°ï¼‰
        super().__init__(cfg=DEFAULT_CFG_DICT, overrides=overrides, _callbacks=_callbacks)

        # æ¢å¤è‡ªå®šä¹‰å‚æ•°åˆ° args
        self.args.kd_temp = self._kd_temp if self._kd_temp is not None else 2.0
        self.args.kd_alpha = self._kd_alpha if self._kd_alpha is not None else 0.5
        self.args.teacher = self._teacher_path

        # è’¸é¦ç›¸å…³å±æ€§
        self.kd_temp = self.args.kd_temp
        self.kd_alpha = self.args.kd_alpha
        self.teacher_model = None

        # æ£€æµ‹ torchrun å¯åŠ¨çš„åˆ†å¸ƒå¼ç¯å¢ƒï¼Œä¿®æ­£ world_size
        import os
        if RANK != -1 and self.world_size == 1:
            # torchrun å¯åŠ¨ï¼Œä½† world_size æœªæ­£ç¡®è®¾ç½®
            world_size_env = os.getenv("WORLD_SIZE")
            if world_size_env:
                self.world_size = int(world_size_env)
                LOGGER.info(f"æ£€æµ‹åˆ° torchrun åˆ†å¸ƒå¼ç¯å¢ƒ: RANK={RANK}, WORLD_SIZE={self.world_size}")

    def get_model(self, cfg=None, weights=None, verbose=True):
        """è¿”å›æ£€æµ‹æ¨¡å‹å¹¶åŠ è½½æ•™å¸ˆæ¨¡å‹ã€‚"""
        model = super().get_model(cfg, weights, verbose)

        # åŠ è½½æ•™å¸ˆæ¨¡å‹
        teacher_path = getattr(self.args, 'teacher', None)
        if teacher_path:
            from ultralytics import YOLO
            LOGGER.info(f"åŠ è½½æ•™å¸ˆæ¨¡å‹: {teacher_path}")
            teacher_yolo = YOLO(teacher_path)
            self.teacher_model = teacher_yolo.model
            self.teacher_model.to(self.device)
            self.teacher_model.eval()

            # å†»ç»“æ•™å¸ˆæ¨¡å‹
            for param in self.teacher_model.parameters():
                param.requires_grad = False
            LOGGER.info(f"æ•™å¸ˆæ¨¡å‹å·²åŠ è½½å¹¶å†»ç»“ (kd_alpha={self.kd_alpha}, kd_temp={self.kd_temp})")

        return model

    def get_loss(self, model):
        """è¿”å›å¸¦çŸ¥è¯†è’¸é¦çš„æŸå¤±å‡½æ•°ã€‚"""
        return v8DetectionLossWithKD(
            model=model,
            teacher_model=self.teacher_model,
            kd_alpha=self.kd_alpha,
            kd_temp=self.kd_temp,
        )

    def _setup_train(self):
        """è®¾ç½®è®­ç»ƒï¼Œä½¿ç”¨è‡ªå®šä¹‰æŸå¤±å‡½æ•°ã€‚"""
        super()._setup_train()

        # æ›¿æ¢æŸå¤±å‡½æ•°ä¸ºå¸¦ KD çš„ç‰ˆæœ¬
        if self.teacher_model is not None:
            model = unwrap_model(self.model)
            self.loss = self.get_loss(model)
            # ç¡®ä¿æ•™å¸ˆæ¨¡å‹åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            self.teacher_model.to(self.device)
            LOGGER.info("å·²å¯ç”¨çŸ¥è¯†è’¸é¦æŸå¤±")

    def get_validator(self):
        """è¿”å›éªŒè¯å™¨ã€‚"""
        self.loss_names = "box_loss", "cls_loss", "dfl_loss"
        return super().get_validator()

    def _setup_ddp(self):
        """åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒå‚æ•°ï¼Œä¿®å¤ LOCAL_RANK é—®é¢˜ã€‚"""
        import os
        from datetime import timedelta
        from torch import distributed as dist

        # ç›´æ¥ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡å—å¯¼å…¥æ—¶çš„å€¼
        local_rank = int(os.getenv("LOCAL_RANK", 0))
        rank = int(os.getenv("RANK", 0))
        world_size = int(os.getenv("WORLD_SIZE", 1))

        LOGGER.info(f"DDP åˆå§‹åŒ–: LOCAL_RANK={local_rank}, RANK={rank}, WORLD_SIZE={world_size}")

        # ä½¿ç”¨ LOCAL_RANK æ¥è®¾ç½® CUDA è®¾å¤‡
        torch.cuda.set_device(local_rank)
        self.device = torch.device("cuda", local_rank)
        os.environ["TORCH_NCCL_BLOCKING_WAIT"] = "1"
        dist.init_process_group(
            backend="nccl" if dist.is_nccl_available() else "gloo",
            timeout=timedelta(seconds=10800),  # 3 hours
            rank=rank,
            world_size=world_size,
        )


# ========== ä¾¿æ·ä½¿ç”¨æ¥å£ ==========

def train(
    model: str = "yolov8s-react.yaml",
    data: str = "coco.yaml",
    epochs: int = 150,
    teacher: str | None = None,
    kd_alpha: float = 0.5,
    kd_temp: float = 2.0,
    batch: int = 16,
    device: str = "0",
    **kwargs
):
    """ä¾¿æ·è®­ç»ƒå…¥å£ã€‚

    ä½¿ç”¨ç¤ºä¾‹:
        # æ™®é€šè®­ç»ƒ
        train(model="yolov8s-react.yaml", data="coco.yaml")

        # è’¸é¦è®­ç»ƒ
        train(model="yolov8s-react.yaml", data="coco.yaml",
              teacher="yolov8s.pt", kd_alpha=0.5)
    """
    overrides = {
        'model': model,
        'data': data,
        'epochs': epochs,
        'batch': batch,
        'device': device,
        'teacher': teacher,
        'kd_alpha': kd_alpha,
        'kd_temp': kd_temp,
        **kwargs
    }

    trainer = ReActNetTrainer(overrides=overrides)
    trainer.train()


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='ReActNet-YOLO è®­ç»ƒ')
    parser.add_argument('--model', type=str, default='yolov8s-react.yaml', help='æ¨¡å‹é…ç½®')
    parser.add_argument('--data', type=str, required=True, help='æ•°æ®é›†é…ç½®')
    parser.add_argument('--epochs', type=int, default=150, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch', type=int, default=16, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--teacher', type=str, default=None, help='æ•™å¸ˆæ¨¡å‹è·¯å¾„')
    parser.add_argument('--kd_alpha', type=float, default=0.5, help='è’¸é¦æƒé‡')
    parser.add_argument('--kd_temp', type=float, default=2.0, help='è’¸é¦æ¸©åº¦')
    parser.add_argument('--device', type=str, default='0', help='è®¾å¤‡')

    args = parser.parse_args()

    train(
        model=args.model,
        data=args.data,
        epochs=args.epochs,
        batch=args.batch,
        teacher=args.teacher,
        kd_alpha=args.kd_alpha,
        kd_temp=args.kd_temp,
        device=args.device,
    )
