# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

from __future__ import annotations

import math
import random
from copy import copy
from typing import Any

import numpy as np
import torch
import torch.nn as nn

from ultralytics.data import build_dataloader, build_yolo_dataset
from ultralytics.engine.trainer import BaseTrainer
from ultralytics.models import yolo
from ultralytics.nn.tasks import DetectionModel
from ultralytics.utils import DEFAULT_CFG, LOGGER, RANK
from ultralytics.utils.patches import override_configs
from ultralytics.utils.plotting import plot_images, plot_labels
from ultralytics.utils.torch_utils import torch_distributed_zero_first, unwrap_model


class DetectionTrainer(BaseTrainer):
    """åŸºäºæ£€æµ‹æ¨¡å‹è®­ç»ƒå™¨çš„æ‰©å±•ç±»ã€‚

    è¯¥è®­ç»ƒå™¨ä¸“é—¨ç”¨äºç›®æ ‡æ£€æµ‹ä»»åŠ¡ï¼Œå¤„ç†è®­ç»ƒYOLOæ¨¡å‹è¿›è¡Œç›®æ ‡æ£€æµ‹çš„ç‰¹å®šéœ€æ±‚ï¼Œ
    åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ•°æ®åŠ è½½ã€é¢„å¤„ç†å’Œæ¨¡å‹é…ç½®ã€‚

    å±æ€§:
        model (DetectionModel): æ­£åœ¨è®­ç»ƒçš„YOLOæ£€æµ‹æ¨¡å‹ã€‚
        data (dict): åŒ…å«æ•°æ®é›†ä¿¡æ¯çš„å­—å…¸ï¼ŒåŒ…æ‹¬ç±»åˆ«åç§°å’Œç±»åˆ«æ•°é‡ã€‚
        loss_names (tuple): è®­ç»ƒä¸­ä½¿ç”¨çš„æŸå¤±ç»„ä»¶åç§° (box_loss, cls_loss, dfl_loss)ã€‚

    æ–¹æ³•:
        build_dataset: ä¸ºè®­ç»ƒæˆ–éªŒè¯æ„å»ºYOLOæ•°æ®é›†ã€‚
        get_dataloader: æ„é€ å¹¶è¿”å›æŒ‡å®šæ¨¡å¼çš„æ•°æ®åŠ è½½å™¨ã€‚
        preprocess_batch: é¢„å¤„ç†ä¸€æ‰¹å›¾åƒï¼ŒåŒ…æ‹¬ç¼©æ”¾å’Œè½¬æ¢ä¸ºæµ®ç‚¹ç±»å‹ã€‚
        set_model_attributes: æ ¹æ®æ•°æ®é›†ä¿¡æ¯è®¾ç½®æ¨¡å‹å±æ€§ã€‚
        get_model: è¿”å›YOLOæ£€æµ‹æ¨¡å‹ã€‚
        get_validator: è¿”å›ç”¨äºæ¨¡å‹è¯„ä¼°çš„éªŒè¯å™¨ã€‚
        label_loss_items: è¿”å›å¸¦æœ‰æ ‡ç­¾çš„è®­ç»ƒæŸå¤±é¡¹å­—å…¸ã€‚
        progress_string: è¿”å›æ ¼å¼åŒ–çš„è®­ç»ƒè¿›åº¦å­—ç¬¦ä¸²ã€‚
        plot_training_samples: ç»˜åˆ¶å¸¦æœ‰æ ‡æ³¨çš„è®­ç»ƒæ ·æœ¬ã€‚
        plot_training_labels: åˆ›å»ºYOLOæ¨¡å‹çš„å¸¦æ ‡ç­¾è®­ç»ƒå›¾ã€‚
        auto_batch: æ ¹æ®æ¨¡å‹å†…å­˜éœ€æ±‚è®¡ç®—æœ€ä¼˜æ‰¹æ¬¡å¤§å°ã€‚

    ç¤ºä¾‹:
        >>> from ultralytics.models.yolo.detect import DetectionTrainer
        >>> args = dict(model="yolo11n.pt", data="coco8.yaml", epochs=3)
        >>> trainer = DetectionTrainer(overrides=args)
        >>> trainer.train()
    """

    def __init__(self, cfg=DEFAULT_CFG, overrides: dict[str, Any] | None = None, _callbacks=None):
        """åˆå§‹åŒ–ç”¨äºè®­ç»ƒYOLOç›®æ ‡æ£€æµ‹æ¨¡å‹çš„DetectionTrainerå¯¹è±¡ã€‚

        å‚æ•°:
            cfg (dict, optional): åŒ…å«è®­ç»ƒå‚æ•°çš„é»˜è®¤é…ç½®å­—å…¸ã€‚
            overrides (dict, optional): é»˜è®¤é…ç½®çš„å‚æ•°å­—å…¸è¦†ç›–ã€‚
            _callbacks (list, optional): åœ¨è®­ç»ƒæœŸé—´æ‰§è¡Œçš„å›è°ƒå‡½æ•°åˆ—è¡¨ã€‚
        """
        super().__init__(cfg, overrides, _callbacks)

    def build_dataset(self, img_path: str, mode: str = "train", batch: int | None = None):
        """ä¸ºè®­ç»ƒæˆ–éªŒè¯æ„å»ºYOLOæ•°æ®é›†ã€‚

        å‚æ•°:
            img_path (str): åŒ…å«å›¾åƒçš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
            mode (str): 'train'æ¨¡å¼æˆ–'val'æ¨¡å¼ï¼Œç”¨æˆ·å¯ä»¥ä¸ºæ¯ç§æ¨¡å¼è‡ªå®šä¹‰ä¸åŒçš„å¢å¼ºã€‚
            batch (int, optional): æ‰¹æ¬¡å¤§å°ï¼Œè¿™ç”¨äº'rect'æ¨¡å¼ã€‚

        è¿”å›:
            (Dataset): ä¸ºæŒ‡å®šæ¨¡å¼é…ç½®çš„YOLOæ•°æ®é›†å¯¹è±¡ã€‚
        """
        gs = max(int(unwrap_model(self.model).stride.max() if self.model else 0), 32)
        return build_yolo_dataset(self.args, img_path, batch, self.data, mode=mode, rect=mode == "val", stride=gs)

    def get_dataloader(self, dataset_path: str, batch_size: int = 16, rank: int = 0, mode: str = "train"):
        """æ„é€ å¹¶è¿”å›æŒ‡å®šæ¨¡å¼çš„æ•°æ®åŠ è½½å™¨ã€‚

        å‚æ•°:
            dataset_path (str): æ•°æ®é›†è·¯å¾„ã€‚
            batch_size (int): æ¯æ‰¹å›¾åƒæ•°é‡ã€‚
            rank (int): åˆ†å¸ƒå¼è®­ç»ƒè¿›ç¨‹æ’åã€‚
            mode (str): 'train'ä¸ºè®­ç»ƒæ•°æ®åŠ è½½å™¨ï¼Œ'val'ä¸ºéªŒè¯æ•°æ®åŠ è½½å™¨ã€‚

        è¿”å›:
            (DataLoader): PyTorchæ•°æ®åŠ è½½å™¨å¯¹è±¡ã€‚
        """
        assert mode in {"train", "val"}, f"æ¨¡å¼å¿…é¡»ä¸º'train'æˆ–'val'ï¼Œè€Œä¸æ˜¯{mode}ã€‚"
        with torch_distributed_zero_first(rank):  # ä»…åœ¨DDPæƒ…å†µä¸‹åˆå§‹åŒ–æ•°æ®é›†*.cacheä¸€æ¬¡
            dataset = self.build_dataset(dataset_path, mode, batch_size)
        shuffle = mode == "train"
        if getattr(dataset, "rect", False) and shuffle:
            LOGGER.warning("'rect=True'ä¸DataLoaderçš„shuffleä¸å…¼å®¹ï¼Œå·²è®¾ç½®shuffle=False")
            shuffle = False
        return build_dataloader(
            dataset,
            batch=batch_size,
            workers=self.args.workers if mode == "train" else self.args.workers * 2,
            shuffle=shuffle,
            rank=rank,
            drop_last=self.args.compile and mode == "train",
        )

    def preprocess_batch(self, batch: dict) -> dict:
        """é¢„å¤„ç†ä¸€æ‰¹å›¾åƒï¼ŒåŒ…æ‹¬ç¼©æ”¾å’Œè½¬æ¢ä¸ºæµ®ç‚¹ç±»å‹ã€‚

        å‚æ•°:
            batch (dict): åŒ…å«æ‰¹æ¬¡æ•°æ®çš„å­—å…¸ï¼Œå…¶ä¸­åŒ…å«'img'å¼ é‡ã€‚

        è¿”å›:
            (dict): å½’ä¸€åŒ–å›¾åƒçš„é¢„å¤„ç†æ‰¹æ¬¡ã€‚
        """
        for k, v in batch.items():
            if isinstance(v, torch.Tensor):
                batch[k] = v.to(self.device, non_blocking=self.device.type == "cuda")
        batch["img"] = batch["img"].float() / 255
        if self.args.multi_scale:
            imgs = batch["img"]
            sz = (
                random.randrange(int(self.args.imgsz * 0.5), int(self.args.imgsz * 1.5 + self.stride))
                // self.stride
                * self.stride
            )  # å°ºå¯¸
            sf = sz / max(imgs.shape[2:])  # ç¼©æ”¾å› å­
            if sf != 1:
                ns = [
                    math.ceil(x * sf / self.stride) * self.stride for x in imgs.shape[2:]
                ]  # æ–°å½¢çŠ¶ï¼ˆæ‹‰ä¼¸åˆ°gså€æ•°ï¼‰
                imgs = nn.functional.interpolate(imgs, size=ns, mode="bilinear", align_corners=False)
            batch["img"] = imgs
        return batch

    def set_model_attributes(self):
        """æ ¹æ®æ•°æ®é›†ä¿¡æ¯è®¾ç½®æ¨¡å‹å±æ€§ã€‚"""
        # Nl = de_parallel(self.model).model[-1].nl  # æ£€æµ‹å±‚æ•°é‡ï¼ˆç”¨äºç¼©æ”¾è¶…å‚æ•°ï¼‰
        # self.args.box *= 3 / nl  # ç¼©æ”¾åˆ°å±‚æ•°
        # self.args.cls *= self.data["nc"] / 80 * 3 / nl  # ç¼©æ”¾åˆ°ç±»åˆ«å’Œå±‚æ•°
        # self.args.cls *= (self.args.imgsz / 640) ** 2 * 3 / nl  # ç¼©æ”¾åˆ°å›¾åƒå¤§å°å’Œå±‚æ•°
        self.model.nc = self.data["nc"]  # å°†ç±»åˆ«æ•°é‡é™„åŠ åˆ°æ¨¡å‹
        self.model.names = self.data["names"]  # å°†ç±»åˆ«åç§°é™„åŠ åˆ°æ¨¡å‹
        self.model.args = self.args  # å°†è¶…å‚æ•°é™„åŠ åˆ°æ¨¡å‹
        # TODO: self.model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device) * nc

    def get_model(self, cfg: str | None = None, weights: str | None = None, verbose: bool = True):
        """è¿”å›YOLOæ£€æµ‹æ¨¡å‹ã€‚

        å‚æ•°:
            cfg (str, optional): æ¨¡å‹é…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚
            weights (str, optional): æ¨¡å‹æƒé‡çš„è·¯å¾„ã€‚
            verbose (bool): æ˜¯å¦æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯ã€‚

        è¿”å›:
            (DetectionModel): YOLOæ£€æµ‹æ¨¡å‹ã€‚
        """
        model = DetectionModel(cfg, nc=self.data["nc"], ch=self.data["channels"], verbose=verbose and RANK == -1)
        if weights:
            model.load(weights)
        return model

    def get_validator(self):
        """è¿”å›ç”¨äºYOLOæ¨¡å‹éªŒè¯çš„DetectionValidatorã€‚"""
        self.loss_names = "box_loss", "cls_loss", "dfl_loss"
        return yolo.detect.DetectionValidator(
            self.test_loader, save_dir=self.save_dir, args=copy(self.args), _callbacks=self.callbacks
        )

    def label_loss_items(self, loss_items: list[float] | None = None, prefix: str = "train"):
        """è¿”å›å¸¦æœ‰æ ‡ç­¾çš„è®­ç»ƒæŸå¤±é¡¹å¼ é‡å­—å…¸ã€‚

        å‚æ•°:
            loss_items (list[float], optional): æŸå¤±å€¼åˆ—è¡¨ã€‚
            prefix (str): è¿”å›å­—å…¸ä¸­é”®çš„å‰ç¼€ã€‚

        è¿”å›:
            (dict | list): å¦‚æœæä¾›äº†loss_itemsåˆ™è¿”å›æŸå¤±é¡¹å­—å…¸ï¼Œå¦åˆ™è¿”å›é”®åˆ—è¡¨ã€‚
        """
        keys = [f"{prefix}/{x}" for x in self.loss_names]
        if loss_items is not None:
            loss_items = [round(float(x), 5) for x in loss_items]  # å°†å¼ é‡è½¬æ¢ä¸º5ä½å°æ•°æµ®ç‚¹æ•°
            return dict(zip(keys, loss_items))
        else:
            return keys

    def progress_string(self):
        """è¿”å›æ ¼å¼åŒ–çš„è®­ç»ƒè¿›åº¦å­—ç¬¦ä¸²ï¼ŒåŒ…æ‹¬è½®æ¬¡ã€GPUå†…å­˜ã€æŸå¤±ã€å®ä¾‹å’Œå¤§å°ã€‚"""
        return ("\n" + "%11s" * (4 + len(self.loss_names))) % (
            "è½®æ¬¡",
            "GPUå†…å­˜",
            *self.loss_names,
            "å®ä¾‹æ•°",
            "å°ºå¯¸",
        )

    def plot_training_samples(self, batch: dict[str, Any], ni: int) -> None:
        """ç»˜åˆ¶å¸¦æœ‰æ ‡æ³¨çš„è®­ç»ƒæ ·æœ¬ã€‚

        å‚æ•°:
            batch (dict[str, Any]): åŒ…å«æ‰¹æ¬¡æ•°æ®çš„å­—å…¸ã€‚
            ni (int): è¿­ä»£æ¬¡æ•°ã€‚
        """
        plot_images(
            labels=batch,
            paths=batch["im_file"],
            fname=self.save_dir / f"train_batch{ni}.jpg",
            on_plot=self.on_plot,
        )

    def plot_training_labels(self):
        """åˆ›å»ºYOLOæ¨¡å‹çš„å¸¦æ ‡ç­¾è®­ç»ƒå›¾ã€‚"""
        boxes = np.concatenate([lb["bboxes"] for lb in self.train_loader.dataset.labels], 0)
        cls = np.concatenate([lb["cls"] for lb in self.train_loader.dataset.labels], 0)
        plot_labels(boxes, cls.squeeze(), names=self.data["names"], save_dir=self.save_dir, on_plot=self.on_plot)

    def auto_batch(self):
        """é€šè¿‡è®¡ç®—æ¨¡å‹çš„å†…å­˜å ç”¨è·å–æœ€ä¼˜æ‰¹æ¬¡å¤§å°ã€‚

        è¿”å›:
            (int): æœ€ä¼˜æ‰¹æ¬¡å¤§å°ã€‚
        """
        with override_configs(self.args, overrides={"cache": False}) as self.args:
            train_dataset = self.build_dataset(self.data["train"], mode="train", batch=16)
        max_num_obj = max(len(label["cls"]) for label in train_dataset.labels) * 4  # 4ç”¨äºé©¬èµ›å…‹å¢å¼º
        del train_dataset  # é‡Šæ”¾å†…å­˜
        return super().auto_batch(max_num_obj)
